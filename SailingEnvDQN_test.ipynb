{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from contextlib import closing\n",
    "import random\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from utils import *\n",
    "from gym import utils, Env, spaces\n",
    "from gym.utils import seeding\n",
    "from gym.envs.toy_text import discrete\n",
    "from gym.utils import seeding\n",
    "from collections import deque\n",
    "from SailingEnvDQN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "\n",
    "MAPS = {\n",
    "#     \"4x4\": [\n",
    "#         \"SFFF\",\n",
    "#         \"FHFH\",\n",
    "#         \"FFFH\",\n",
    "#         \"HFFG\"\n",
    "#     ],\n",
    "    \"8x8\": [\n",
    "        \"SWWOOWWD\",\n",
    "        \"WWWOOWWW\",\n",
    "        \"WWWWWWWW\",\n",
    "        \"WWWWWWWW\",\n",
    "        \"OOWWWWWW\",\n",
    "        \"WWWWWWWW\",\n",
    "        \"WWWWWWOO\",\n",
    "        \"DWWWWWWD\"\n",
    "    ],\n",
    "    \"16x16\": [\n",
    "        \"SWWWWWWWWWWOOWWD\",\n",
    "        \"WWWWWWWWWWWOOWWW\",\n",
    "        \"WWWWWWWWWWWWWWWW\",\n",
    "        \"WWWWOOOWWWWWWWWW\",\n",
    "        \"WWWWOOOWWWWWWWWW\",\n",
    "        \"WWWWWWWWWWWWWWWW\",\n",
    "        \"OOOWWWWWWWWWWOOO\",\n",
    "        \"OOOWWWWWWWWWWOOO\",\n",
    "        \"WWWWWWWWWWWWWWWW\",\n",
    "        \"WWWWWWOOOWWWWWWW\",\n",
    "        \"WWWWWWOOOWWWWWWW\",\n",
    "        \"WWWWWWWWWWWWWWWW\",\n",
    "        \"OOOWWWWWWWWWWWWW\",\n",
    "        \"OOOWWWWWWWWWWWWW\",\n",
    "        \"WWWWWWWWWWOOOOOO\",\n",
    "        \"DWWWWWWWWWWWWWWD\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "rewards_dict = {\n",
    "    \"8x8\":\n",
    "    {\n",
    "        7 : 2.0,\n",
    "        56 : 4.0,\n",
    "        63 : 10.0\n",
    "    },\n",
    "    \"16x16\":\n",
    "    {\n",
    "        15: 400.0,\n",
    "        240: 800.0,\n",
    "        255 : 2000.0\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def categorical_sample(prob_n, np_random):\n",
    "    \"\"\"\n",
    "    Sample from categorical distribution\n",
    "    Each row specifies class probabilities\n",
    "    \"\"\"\n",
    "    prob_n = np.asarray(prob_n)\n",
    "    csprob_n = np.cumsum(prob_n)\n",
    "    return (csprob_n > np_random.rand()).argmax()\n",
    "\n",
    "def get_destination(MAP):\n",
    "            destination = []\n",
    "            row = len(MAP)\n",
    "            col = len(MAP[row-1])\n",
    "\n",
    "            for i in range(row):\n",
    "                for j in range(col):\n",
    "\n",
    "                    newletter = MAP[i][j]\n",
    "                    if newletter == \"D\":\n",
    "\n",
    "                        destination.append(i*col + j)\n",
    "            return destination\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SailingEnvDQN():\n",
    "\n",
    "    metadata = {'render.modes': ['human', 'ansi']}\n",
    "    def __init__(self, config):\n",
    "#         if desc is None and map_name is None:\n",
    "#             desc = generate_random_map()\n",
    "#         elif desc is None:\n",
    "#             desc = MAPS[map_name]\n",
    "        \n",
    "        self.map_name = config[\"map_name\"]\n",
    "        desc = MAPS[self.map_name]\n",
    "        is_slippery=config[\"is_slippery\"]\n",
    "        self.current_step = 0\n",
    "        \n",
    "        self.total_steps = config[\"total_steps\"] \n",
    "        self.destinations = get_destination(desc)\n",
    "        self.total_destinations = len(self.destinations)\n",
    "        self.destinations_dict = {D: False for D in self.destinations}\n",
    "        self.num_reached_destinations = 0\n",
    "        \n",
    "        if config[\"is_random_env\"] == False:\n",
    "            self.random_seed = config[\"random_seed\"]\n",
    "            random.seed(self.random_seed)\n",
    "            \n",
    "        self.desc = desc = np.asarray(desc, dtype='c')\n",
    "        self.nrow, self.ncol = nrow, ncol = desc.shape\n",
    "        self.reward_range = (0, self.total_destinations)\n",
    "        self.initial_state = np.array([0,0])\n",
    "        self.current_state = self.initial_state\n",
    "        self.nA = 4\n",
    "        self.nS = 2\n",
    "        self.action_space = spaces.Discrete(self.nA)\n",
    "        self.observation_space = spaces.Discrete(self.nS)\n",
    "        self.seed()\n",
    "        self.isd = np.array(desc == b'S').astype('float64').ravel()\n",
    "        self.isd /= self.isd.sum()\n",
    "        \n",
    "    def transition_dynamics(self, action, state):\n",
    "        # given the action (direction), calculate the next state (UAV current position)\n",
    "        assert action in self.action_space\n",
    "        row, col = state[0], state[1]\n",
    "        next_state = list((row, col))\n",
    "        if action == 0:\n",
    "            # move up\n",
    "            next_state[1] = max(col - 1, 0)\n",
    "        if action == 1:\n",
    "            # move right\n",
    "            next_state[0] = min(row + 1, self.nrow - 1)\n",
    "        if action == 2:\n",
    "            # move down\n",
    "            next_state[1] = min(col + 1, self.ncol - 1)\n",
    "        if action == 3:\n",
    "            # move left\n",
    "            next_state[0]  = max(row - 1, 0)\n",
    "        return np.array(next_state)\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        \n",
    "    def to_s(self, row, col):\n",
    "            return row*self.ncol + col\n",
    "        \n",
    "    def update_reached_destinations(self, newstate):\n",
    "        if newstate in self.destinations_dict:\n",
    "            if self.destinations_dict[newstate] == False:\n",
    "                self.destinations_dict[newstate] = True\n",
    "                self.num_reached_destinations +=1\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    def step(self, action):\n",
    "        # assume we use the max speed as the default speed, when come near to the opt-position, we can slow down the speed\n",
    "\n",
    "        \n",
    "        prev_state = self.current_state\n",
    "        #update pos\n",
    "        self.current_state = self.transition_dynamics(action, self.current_state)\n",
    "        \n",
    "        newstate = self.to_s(self.current_state[0], self.current_state[1])\n",
    "#         print(self.desc)\n",
    "#         print(newstate)\n",
    "        newletter = self.desc[self.current_state[0]][self.current_state[1]]\n",
    "        \n",
    "        self.current_step = self.current_step + 1\n",
    "        s_updated_destinations = self.update_reached_destinations(newstate)\n",
    "        \n",
    "        self.s = newstate\n",
    "        self.lastaction = action\n",
    "        \n",
    "        done = bytes(newletter) in b'OD'\n",
    "        if self.current_step == self.total_steps:\n",
    "            done =  True\n",
    "            \n",
    "        reward = 0.0\n",
    "        \n",
    "        if done != True:\n",
    "            self.current_step += 1\n",
    "        else:\n",
    "            reward -= self.current_step\n",
    "\n",
    "        \n",
    "        return self.current_state, reward, done\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.current_state = self.initial_state\n",
    "        self.lastaction = None\n",
    "        self.num_reached_destinations = 0\n",
    "\n",
    "        self.destinations_dict = {D: False for D in self.destinations}\n",
    "        \n",
    "        return self.current_state\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
    "\n",
    "        row, col = self.s // self.ncol, self.s % self.ncol\n",
    "        desc = self.desc.tolist()\n",
    "        desc = [[c.decode('utf-8') for c in line] for line in desc]\n",
    "        desc[row][col] = utils.colorize(desc[row][col], \"red\", highlight=True)\n",
    "        if self.lastaction is not None:\n",
    "            outfile.write(\"  ({})\\n\".format(\n",
    "                [\"Left\", \"Down\", \"Right\", \"Up\"][self.lastaction]))\n",
    "        else:\n",
    "            outfile.write(\"\\n\")\n",
    "        outfile.write(\"\\n\".join(''.join(line) for line in desc)+\"\\n\")\n",
    "\n",
    "        if mode != 'human':\n",
    "            with closing(outfile):\n",
    "                return outfile.getvalue()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_config = dict(\n",
    "    total_steps = 1000,\n",
    "    random_seed = 10,\n",
    "    is_random_env = False,\n",
    "    map_name = \"16x16\",  \n",
    "    is_slippery = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SailingEnvDQN(environment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SWWWWWWWWWWOOWWD\n",
      "WWWWWWWWWWWOOWWW\n",
      "WWWWWWWWWWWWWWWW\n",
      "WWWWOOOWWWWWWWWW\n",
      "WWWW\u001b[41mO\u001b[0mOOWWWWWWWWW\n",
      "WWWWWWWWWWWWWWWW\n",
      "OOOWWWWWWWWWWOOO\n",
      "OOOWWWWWWWWWWOOO\n",
      "WWWWWWWWWWWWWWWW\n",
      "WWWWWWOOOWWWWWWW\n",
      "WWWWWWOOOWWWWWWW\n",
      "WWWWWWWWWWWWWWWW\n",
      "OOOWWWWWWWWWWWWW\n",
      "OOOWWWWWWWWWWWWW\n",
      "WWWWWWWWWWOOOOOO\n",
      "DWWWWWWWWWWWWWWD\n",
      "Current step: 205\n",
      "Current observation: [4 4]\n",
      "Current reward: -205.0\n",
      "Whether we are done: True\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # take random action\n",
    "    # [TODO] Uncomment next line\n",
    "    obs, reward, done = env.step(env.action_space.sample())\n",
    "\n",
    "    # render the environment\n",
    "    env.render()  # [TODO] Uncomment this line\n",
    "\n",
    "    print(\"Current step: {}\\nCurrent observation: {}\\nCurrent reward: {}\\n\"\n",
    "          \"Whether we are done: {}\".format(\n",
    "        env.current_step, obs, reward, done\n",
    "    ))\n",
    "    wait(sleep=0.4)\n",
    "    # [TODO] terminate the loop if done\n",
    "    if done:\n",
    "        break\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 34]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list((24,34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_state[0], env.current_state[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'D'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.desc[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deque(maxlen=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
